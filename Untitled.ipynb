{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import time\n",
    "import random\n",
    "from concurrent.futures import ProcessPoolExecutor as prpExecutor\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# Data File Path\n",
    "# ============================\n",
    "DATA_FILE_PATH = \"/hdd1/Spoiler_Detection/ACL/INGGEOL/node_edge_info_10000_new.json\"\n",
    "\n",
    "# ============================\n",
    "# Model Hyper Parameter\n",
    "# ============================\n",
    "EMBEDDING_DIM = 50\n",
    "HIDDEN_STATES = [50, 50]\n",
    "\n",
    "# ============================\n",
    "# Training Hyper Parameter\n",
    "# ============================\n",
    "EPOCHS = 100\n",
    "LEARNING_RATE = 0.00005\n",
    "BATCH_SIZE = 256\n",
    "WEIGHT_DECAY = 1e-5\n",
    "DROPOUT_RATE = 0.5\n",
    "RANDOM_SEED = 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# Data Pre-Processing\n",
    "# ============================\n",
    "def load_data(file_path):\n",
    "    data = []\n",
    "    with open(file_path) as f:\n",
    "        _data = json.load(f)\n",
    "    for review in _data:\n",
    "        data += review[\"text_info\"]\n",
    "    return data\n",
    "\n",
    "def make_dictionary(data):\n",
    "    maximum_length = max([len(line.split(\"\\t\")[0].split()) for line in data])\n",
    "\n",
    "    word2id = {\"<PAD>\":0}\n",
    "    id2word = [\"<PAD>\"]\n",
    "    edge2id = {}\n",
    "    id2edge = []\n",
    "    \n",
    "    for line in data:\n",
    "        tokens = line.split(\"\\t\")\n",
    "        for word in tokens[0].split():\n",
    "            if word not in word2id:\n",
    "                word2id[word] = len(word2id)\n",
    "                id2word.append(word)\n",
    "        for edges in tokens[2:]:\n",
    "            _tokens = edges.split(\":\")\n",
    "            if len(_tokens) != 3:\n",
    "                start, end = _tokens[0], _tokens[1]\n",
    "                edge = \":\".join(_tokens[2:])\n",
    "            else:\n",
    "                start, end, edge = _tokens\n",
    "            if edge not in edge2id:\n",
    "                edge2id[edge] = len(edge2id)\n",
    "                id2edge.append(edge)\n",
    "\n",
    "    return word2id, id2word, edge2id, id2edge, maximum_length\n",
    "\n",
    "def make_input_data_as_index(_data, word2id, edge2id):\n",
    "    data = []\n",
    "    for line in _data:\n",
    "        tokens = line.split(\"\\t\")\n",
    "        tokens[0] = [word2id[word] for word in tokens[0].split()]\n",
    "        _edges = []\n",
    "        for edges in tokens[2:]:\n",
    "            _tokens = edges.split(\":\")\n",
    "            if len(_tokens) != 3:\n",
    "                start, end = _tokens[0], _tokens[1]\n",
    "                edge = \":\".join(_tokens[2:])\n",
    "            else:\n",
    "                start, end, edge = _tokens\n",
    "            _edges.append([start, end, edge2id[edge]])\n",
    "        data.append([tokens[0], tokens[1], _edges])\n",
    "        \n",
    "    return data\n",
    "\n",
    "def make_input_adjacency_matrix(_data):\n",
    "    data = []\n",
    "    for line in _data:\n",
    "        words, label, edges = line[0], float(line[1]), line[2]\n",
    "        adjacency_matrix = make_adjacency_matrix(np.asarray(edges), len(words))\n",
    "        data.append([words, adjacency_matrix, label])\n",
    "    \n",
    "    return data\n",
    "\n",
    "def normalize_matrix(matrix):\n",
    "    rowsum = np.asarray(matrix.sum(1))\n",
    "    row_inv = np.power(np.sqrt(rowsum), -1).flatten()\n",
    "    row_inv[np.isinf(row_inv)] = 0.\n",
    "    row_matrix_inv = sp.diags(row_inv)\n",
    "    matrix = row_matrix_inv.dot(matrix)\n",
    "\n",
    "    return matrix\n",
    "\n",
    "def sparse_matrix_to_torch_sparse_tensor(sparse_matrix, maximum_length):\n",
    "    sparse_matrix = sparse_matrix.tocoo().astype(np.float32)\n",
    "    indices = torch.from_numpy(\n",
    "        np.vstack((sparse_matrix.row, sparse_matrix.col)).astype(np.int64))\n",
    "    values = torch.from_numpy(sparse_matrix.data)\n",
    "    shape = torch.Size((maximum_length, maximum_length))\n",
    "\n",
    "    return torch.sparse.FloatTensor(indices, values, shape)\n",
    "\n",
    "def make_adjacency_matrix(edges, num_words):\n",
    "    adjacency_matrix = sp.coo_matrix(\n",
    "        (np.ones(len(edges)), (edges[:, 0].astype(np.int32), edges[:, 1].astype(np.int32))),\n",
    "        shape=(num_words, num_words),\n",
    "        dtype=np.float32\n",
    "    )\n",
    "    \n",
    "    identity_matrix = sp.coo_matrix(\n",
    "        (np.ones(len(edges)), (np.arange(len(edges)), np.arange(len(edges)))),\n",
    "        shape=(num_words, num_words),\n",
    "        dtype=np.float32\n",
    "    )\n",
    "    \n",
    "    adjacency_matrix = adjacency_matrix + identity_matrix + adjacency_matrix.transpose()\n",
    "    normalized_adjacency_matrix = normalize_matrix(adjacency_matrix)\n",
    "    \n",
    "    return normalized_adjacency_matrix\n",
    "\n",
    "def make_batch(data, batch_size, is_train=True):\n",
    "    indices = np.arange(len(data))\n",
    "    if is_train:\n",
    "        random.shuffle(indices)\n",
    "    \n",
    "    if len(data) % batch_size == 0:\n",
    "        batch_num = int(len(data)/batch_size)\n",
    "    else:\n",
    "        batch_num = int(len(data)/batch_size) + 1\n",
    "        \n",
    "    for i in range(batch_num):\n",
    "        left = i*batch_size\n",
    "        right = min((i+1)*batch_size, len(data))\n",
    "        \n",
    "        sentences = []\n",
    "        adjacency_matrics = []\n",
    "        labels = []\n",
    "        \n",
    "        for j in indices[left:right]:\n",
    "            sentences.append(data[j][0])\n",
    "            adjacency_matrics.append(data[j][1])\n",
    "            labels.append(data[j][2])\n",
    "        \n",
    "        yield sentences, adjacency_matrics, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Data...\n",
      "Make Dictionary...\n",
      "Make Input as Index...\n",
      "Make Adjacency Matrix...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/buru/python3_venv/lib/python3.5/site-packages/ipykernel_launcher.py:68: RuntimeWarning: divide by zero encountered in power\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "332\n",
      "Make Sparse Tensor...\n",
      "1529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-16:\n",
      "Process Process-14:\n",
      "Process Process-15:\n",
      "Process Process-12:\n",
      "Process Process-9:\n",
      "Traceback (most recent call last):\n",
      "Process Process-7:\n",
      "Process Process-6:\n",
      "Process Process-5:\n",
      "Process Process-10:\n",
      "Process Process-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Process Process-8:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Process Process-11:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process Process-3:\n",
      "Process Process-13:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process Process-2:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Process Process-1:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/concurrent/futures/process.py\", line 169, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/concurrent/futures/process.py\", line 169, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/concurrent/futures/process.py\", line 169, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/concurrent/futures/process.py\", line 169, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/concurrent/futures/process.py\", line 169, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.5/concurrent/futures/process.py\", line 169, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/concurrent/futures/process.py\", line 169, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.5/concurrent/futures/process.py\", line 169, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/concurrent/futures/process.py\", line 169, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/concurrent/futures/process.py\", line 169, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/concurrent/futures/process.py\", line 169, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/concurrent/futures/process.py\", line 169, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.5/concurrent/futures/process.py\", line 169, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/concurrent/futures/process.py\", line 169, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/concurrent/futures/process.py\", line 169, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/concurrent/futures/process.py\", line 169, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 94, in get\n",
      "    res = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Data Pre Processing\n",
    "# ============================\n",
    "print(\"Load Data...\")\n",
    "data = load_data(DATA_FILE_PATH)\n",
    "\n",
    "print(\"Make Dictionary...\")\n",
    "word2id, id2word, edge2id, id2edge, maximum_length = make_dictionary(data)\n",
    "\n",
    "print(\"Make Input as Index...\")\n",
    "data = make_input_data_as_index(data, word2id, edge2id)\n",
    "\n",
    "print(\"Make Adjacency Matrix...\")\n",
    "start = time.time()\n",
    "pool = prpExecutor(max_workers=16)\n",
    "data = list(pool.map(make_input_adjacency_matrix, [data]))[0]\n",
    "print(int(time.time() - start))\n",
    "\n",
    "print(\"Make Sparse Tensor...\")\n",
    "start = time.time()\n",
    "for line in data:\n",
    "    line[0] += [0] * (maximum_length - len(line[0]))\n",
    "    line[1] = sparse_matrix_to_torch_sparse_tensor(line[1], maximum_length)\n",
    "print(int(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# Model\n",
    "# ============================\n",
    "class GCNLayer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(GCNLayer, self).__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        self.weight = nn.Parameter(\n",
    "            torch.randn(self.input_dim, self.output_dim))\n",
    "        nn.init.xavier_normal_(self.weight)\n",
    "\n",
    "        self.bias = nn.Parameter(torch.zeros(self.output_dim))\n",
    "\n",
    "    def forward(self, x, adj_matrics):\n",
    "        x = torch.matmul(adj_matrics, x)\n",
    "        output = torch.matmul(x, self.weight)\n",
    "        output = output + self.bias\n",
    "\n",
    "        return output\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, num_words, embedding_dim, hidden_dim, maximum_length, dropout_rate):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.num_words = num_words\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.maximum_length = maximum_length\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        # =============================================\n",
    "        # Data Preparation\n",
    "        # =============================================\t\t\n",
    "        self.word_embedding \\\n",
    "        = nn.Embedding(self.num_words, self.embedding_dim, padding_idx = 0)\n",
    "        nn.init.xavier_normal_(self.word_embedding.weight)\n",
    "        self.gcn_layer_1 \\\n",
    "        = GCNLayer(self.embedding_dim, self.hidden_dim[0])\n",
    "        self.gcn_layer_2 \\\n",
    "        = GCNLayer(self.hidden_dim[0], self.hidden_dim[1])\n",
    "        \n",
    "        self.max_pooling = nn.MaxPool1d(self.maximum_length)\n",
    "        self.output_layer = nn.Linear(self.hidden_dim[1], 1)\n",
    "\n",
    "    def forward(self, sentences, adjacency_matrics, batch_size):\n",
    "        embedded_words = self.word_embedding(sentences)\n",
    "        gcn_1 = self.gcn_layer_1(embedded_words, adjacency_matrics)\n",
    "        gcn_1 = F.relu(gcn_1)\n",
    "        gcn_1 = F.dropout(gcn_1, self.dropout_rate)\n",
    "        gcn_2 = self.gcn_layer_2(gcn_1, adjacency_matrics)\n",
    "        gcn_2 = F.relu(gcn_2)\n",
    "        sentence_representations = self.max_pooling(gcn_2.transpose(1, 2)).squeeze()\n",
    "        sentence_representations = F.dropout(sentence_representations, self.dropout_rate)\n",
    "        output = self.output_layer(sentence_representations)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Initializing..\n"
     ]
    }
   ],
   "source": [
    "# =============================================\n",
    "# Model Initialize\n",
    "# =============================================\n",
    "print(\"Model Initializing..\")\n",
    "pos_weight = 20*torch.ones([1])\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "model = Model(len(word2id), EMBEDDING_DIM, HIDDEN_STATES, maximum_length, DROPOUT_RATE)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Training..\n",
      "\n",
      "[0/514]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-5408e34572f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0minput_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_adjacency_matrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0m_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0m_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python3_venv/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-67-a8b9c1847f0d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sentences, adjacency_matrics, batch_size)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mgcn_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcn_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mgcn_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcn_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mgcn_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgcn_layer_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcn_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madjacency_matrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mgcn_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcn_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0msentence_representations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pooling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcn_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python3_venv/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-67-a8b9c1847f0d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, adj_matrics)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj_matrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madj_matrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# =============================================\n",
    "# Model Training\n",
    "# =============================================\n",
    "print(\"Model Training..\\n\")\n",
    "for i in range(EPOCHS):\n",
    "    model.train()\n",
    "    start = time.time()\n",
    "    \n",
    "    if len(data) % BATCH_SIZE == 0:\n",
    "        batch_num = int(len(data)/BATCH_SIZE)\n",
    "    else:\n",
    "        batch_num = int(len(data)/BATCH_SIZE) + 1\n",
    "    \n",
    "    loss = .0\n",
    "    batches = make_batch(data, BATCH_SIZE)\n",
    "    step = 0\n",
    "    for batch in batches:\n",
    "        sentences, adjacency_matrics, labels = batch\n",
    "        input_sentences = torch.tensor(sentences, dtype = torch.long)\n",
    "        input_adjacency_matrics = torch.stack([matrix.to_dense() for matrix in adjacency_matrics], dim=0)\n",
    "        input_labels = torch.tensor(labels, dtype=torch.float32)\n",
    "        optimizer.zero_grad()\n",
    "        predicted = model(input_sentences, input_adjacency_matrics, len(sentences))\n",
    "        _loss = criterion(predicted, input_labels.unsqueeze(dim=1)).sum()\n",
    "        _loss.backward()\n",
    "        optimizer.step()\n",
    "        loss += _loss.item()\n",
    "        step+=1\n",
    "        \n",
    "        sys.stdout.flush()\n",
    "        sys.stdout.write(\"\\r\" + \"[{}/{}]\".format(step, batch_num))\n",
    "    print(\"Loss: {}\\n\".format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEX\n",
      "9"
     ]
    }
   ],
   "source": [
    "print(\"SEX\")\n",
    "for i in range(10):\n",
    "    sys.stdout.flush()\n",
    "    sys.stdout.write(\"\\r\" + \"{}\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
